services:
  # Nginx - Reverse Proxy z SSL
  nginx:
    image: nginx:alpine
    container_name: nginx-proxy
    restart: unless-stopped
    ports:
      - "8080:80"
      - "8443:443"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - open-webui
      - litellm
    networks:
      - ai-network

  # PostgreSQL - baza danych dla LiteLLM
  postgres:
    image: postgres:16-alpine
    container_name: litellm-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=litellm
      - POSTGRES_USER=litellm
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - ai-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U litellm -d litellm"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Open WebUI - interfejs użytkownika dla LLM
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: unless-stopped
    expose:
      - "8080"
    volumes:
      - open-webui-data:/app/backend/data
    environment:
      # Połączenie z LiteLLM jako proxy
      - OPENAI_API_BASE_URL=http://litellm:4000/v1
      - OPENAI_API_KEY=sk-password
      # Opcjonalne ustawienia
      - WEBUI_AUTH=true
      - WEBUI_NAME=Open WebUI
    depends_on:
      postgres:
        condition: service_healthy
      litellm:
        condition: service_healthy
    networks:
      - ai-network

  # LiteLLM - gateway/proxy dla różnych dostawców LLM
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    restart: unless-stopped
    ports:
      - "4000:4000"
    volumes:
      - ./config/litellm/config.yaml:/app/config.yaml
      # Montowanie pliku .env z kluczami API
      - ./config/litellm/.env:/app/.env
    environment:
      # Ścieżka do pliku konfiguracyjnego
      - CONFIG_FILE=/app/config.yaml
      # Załaduj zmienne środowiskowe z pliku .env
      - LITELLM_MASTER_KEY=sk-1z4bxV6OoK
      # PostgreSQL connection
      - DATABASE_URL=postgresql://litellm:bmFj5xF07m@postgres:5432/litellm
      # Włącz przechowywanie modeli w bazie danych
      - STORE_MODEL_IN_DB=True
    env_file:
      # Plik .env z kluczami API dla różnych dostawców
      - ./config/litellm/.env
    command: 
      - "--config"
      - "/app/config.yaml"
      - "--port"
      - "4000"
      - "--detailed_debug"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - ai-network
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; req = urllib.request.Request('http://localhost:4000/health', headers={'Authorization': 'Bearer sk-1z4bxV6OoK'}); urllib.request.urlopen(req, timeout=5)\" || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

networks:
  ai-network:
    driver: bridge

volumes:
  open-webui-data:
    driver: local
  postgres-data:
    driver: local
